{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eNq4lCSSQWn"
      },
      "source": [
        "**Instituto Tecnológico de Costa Rica - TEC**\n",
        "\n",
        "***Inteligencia Artificial***\n",
        "\n",
        "*Docente: Kenneth Obando Rodríguez*\n",
        "\n",
        "---\n",
        "# Trabajo Corto 3: Árboles de Decisión\n",
        "---\n",
        "Estudiantes:\n",
        "- Ariel Leyva c.2022175018\n",
        "\n",
        "Link del Cuaderno (recuerde configurar el acceso a público):\n",
        "\n",
        "    \n",
        "- [Link de su respuesta](https://github.com/hart-venus/tc4-ia/)\n",
        "\n",
        "    **Nota:** Este trabajo tiene como objetivo promover la comprensión de la materia y su importancia en la elección de algoritmos. Los alumnos deben evitar copiar y pegar directamente información de fuentes externas, y en su lugar, demostrar su propio análisis y comprensión.\n",
        "\n",
        "### Entrega\n",
        "Debe entregar un archivo comprimido por el TecDigital, incluyendo un documento pdf con los resultados de los experimentos y pruebas. La fecha de entrega es el miércoles 1 de mayo a las 10:00 p.m."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmAGdF_-Xhj1"
      },
      "source": [
        "Instrucciones:\n",
        "\n",
        "Las alternativas se rifarán en clase utilizando números aleatorios. Deberá realizar la asignación propuesta. Si realiza ambos ejercicios, recibirá 20 puntos en **la nota porcentual de la actividad**, para aplicar a la totalidad de los puntos extra es necesario que ambas actividades se completen al 100%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onCmI27E3Jit"
      },
      "source": [
        "## Actividad - Taller\n",
        "\n",
        "1. Cree una clase nodo con atributos necesarios para un árbol de decisión: feature, umbral, gini, cantidad_muestras, valor, izquierda, derecha\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "class Nodo:\n",
        "    def __init__(self, feature=None, umbral=None, gini=None, cantidad_muestras=None, valor=None, izquierda=None, derecha=None):\n",
        "        self.feature = feature  # Índice de la característica (feature) para la división\n",
        "        self.umbral = umbral  # Valor umbral para la división\n",
        "        self.gini = gini  # Impureza de Gini en el nodo\n",
        "        self.cantidad_muestras = cantidad_muestras  # Cantidad de muestras en el nodo\n",
        "        self.valor = valor  # Valor de predicción (para nodos hoja)\n",
        "        self.izquierda = izquierda  # Nodo hijo izquierdo\n",
        "        self.derecha = derecha  # Nodo hijo derecho\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explicación de los atributos:\n",
        "\n",
        "- feature: Representa el índice de la característica (feature) utilizada para la división en el nodo. Es None para los nodos hoja.\n",
        "- umbral: Representa el valor umbral utilizado para la división en el nodo. Las muestras con valores menores o iguales al umbral se envían al nodo hijo izquierdo, mientras que las muestras con valores mayores se envían al nodo hijo derecho. Es None para los nodos hoja.\n",
        "- gini: Representa la impureza de Gini en el nodo, que mide la calidad de la división. Un valor de Gini más bajo indica una división más pura.\n",
        "- cantidad_muestras: Representa la cantidad de muestras que llegan al nodo durante el entrenamiento del árbol.\n",
        "- valor: Representa el valor de predicción para los nodos hoja. En un árbol de clasificación, suele ser la clase mayoritaria entre las muestras que llegan al nodo hoja. En un árbol de regresión, puede ser el promedio de los valores de las muestras en el nodo hoja.\n",
        "- izquierda: Representa el nodo hijo izquierdo, que contiene las muestras con valores menores o iguales al umbral de división. Es None para los nodos hoja.\n",
        "- derecha: Representa el nodo hijo derecho, que contiene las muestras con valores mayores al umbral de división. Es None para los nodos hoja.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Crea una clase que implementa un árbol de decisión, utilice las funciones presentadas en clase, además incluya los siguientes hyperparámetros:\n",
        "   - max_depth: Cantidad máxima de variables que se pueden explorar\n",
        "   - min_split_samples: Cantidad mínima de muestras que deberá tener un nodo para poder ser dividido\n",
        "   - criterio: función que se utilizará para calcular la impuridad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ArbolDecision:\n",
        "    def __init__(self, max_depth=None, min_split_samples=2, criterio='gini'):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_split_samples = min_split_samples\n",
        "        self.criterio = criterio\n",
        "        self.root = None\n",
        "\n",
        "    def _calcular_gini(self, y):\n",
        "        _, counts = np.unique(y, return_counts=True) # cuenta las ocurrencias de cada clase\n",
        "        proporciones = counts / len(y) # calcula la proporción de cada clase\n",
        "        gini = 1 - np.sum(proporciones ** 2) # calcula la impureza de Gini\n",
        "        return gini \n",
        "\n",
        "    def _dividir(self, X, y, feature, umbral):\n",
        "        izquierda_indices = X[:, feature] <= umbral\n",
        "        derecha_indices = X[:, feature] > umbral # Divide basado en los umbrales\n",
        "        X_izquierda, y_izquierda = X[izquierda_indices], y[izquierda_indices]\n",
        "        X_derecha, y_derecha = X[derecha_indices], y[derecha_indices]\n",
        "        return X_izquierda, y_izquierda, X_derecha, y_derecha\n",
        "\n",
        "    def _construir_arbol(self, X, y, depth=0):\n",
        "        cantidad_muestras = len(y)\n",
        "        if cantidad_muestras < self.min_split_samples or depth == self.max_depth: # caso base\n",
        "            valor = np.bincount(y).argmax()\n",
        "            return Nodo(cantidad_muestras=cantidad_muestras, valor=valor)\n",
        "\n",
        "        mejor_feature, mejor_umbral, mejor_gini = None, None, float('inf')\n",
        "        for feature in range(X.shape[1]):\n",
        "            umbrales = np.unique(X[:, feature])\n",
        "            for umbral in umbrales: # construye el arbol por cada umbral\n",
        "                X_izquierda, y_izquierda, X_derecha, y_derecha = self._dividir(X, y, feature, umbral)\n",
        "                if len(y_izquierda) > 0 and len(y_derecha) > 0: # si hay muestras en ambos nodos hijos\n",
        "                    gini_izquierda = self._calcular_gini(y_izquierda)\n",
        "                    gini_derecha = self._calcular_gini(y_derecha)\n",
        "                    gini = (len(y_izquierda) * gini_izquierda + len(y_derecha) * gini_derecha) / cantidad_muestras\n",
        "                    if gini < mejor_gini:\n",
        "                        mejor_feature, mejor_umbral, mejor_gini = feature, umbral, gini\n",
        "\n",
        "        if mejor_feature is None: # si no se puede dividir, caso base\n",
        "            valor = np.bincount(y).argmax()\n",
        "            return Nodo(cantidad_muestras=cantidad_muestras, valor=valor)\n",
        "\n",
        "        X_izquierda, y_izquierda, X_derecha, y_derecha = self._dividir(X, y, mejor_feature, mejor_umbral)\n",
        "        nodo_izquierdo = self._construir_arbol(X_izquierda, y_izquierda, depth + 1) # crear hijos recursivamente\n",
        "        nodo_derecho = self._construir_arbol(X_derecha, y_derecha, depth + 1)\n",
        "\n",
        "        return Nodo(feature=mejor_feature, umbral=mejor_umbral, gini=mejor_gini,\n",
        "                    cantidad_muestras=cantidad_muestras, izquierda=nodo_izquierdo, derecha=nodo_derecho)\n",
        "\n",
        "    def fit(self, X, y): # metodo publico para entrenar el modelo\n",
        "        self.root = self._construir_arbol(X, y)\n",
        "\n",
        "    def _predecir(self, x, nodo): \n",
        "        if nodo.valor is not None:\n",
        "            return nodo.valor\n",
        "        if x[nodo.feature] <= nodo.umbral:\n",
        "            return self._predecir(x, nodo.izquierda)\n",
        "        else:\n",
        "            return self._predecir(x, nodo.derecha)\n",
        "\n",
        "    def predict(self, X): # metodo publico para hacer predicciones\n",
        "        return np.array([self._predecir(x, self.root) for x in X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Divida los datos en los conjuntos tradicionales de entrenamiento y prueba, de forma manual, sin utilizar las utilidades de sklearn (puede utilizar índices de Numpy o Pandas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar datos de prueba (Iris dataset)\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba utilizando índices de NumPy\n",
        "indices = np.arange(len(X))\n",
        "np.random.shuffle(indices)\n",
        "train_size = int(0.8 * len(X))\n",
        "train_indices = indices[:train_size]\n",
        "test_indices = indices[train_size:]\n",
        "X_train, y_train = X[train_indices], y[train_indices]\n",
        "X_test, y_test = X[test_indices], y[test_indices]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Implemente una función que se llame `validacion_cruzada` que entrene $k$ modelos y reporte las métricas obtenidas:\n",
        "  a. Divida el conjunto de entrenamiento en $k$ subconjuntos excluyentes\n",
        "  b. Para cada uno de los $k$ modelos, utilice un subconjunto como validación\n",
        "  c. Reporte la media y la desviación estándar para cada una de las métricas, todo debe realizarse solo usando Numpy:\n",
        "    - Accuracy\n",
        "    - Precision\n",
        "    - Recall\n",
        "    - F1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validacion_cruzada(modelo, X, y, k=5):\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    fold_sizes = np.full(k, len(X) // k, dtype=int)\n",
        "    fold_sizes[:len(X) % k] += 1\n",
        "    current = 0\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for fold_size in fold_sizes:\n",
        "        start, stop = current, current + fold_size\n",
        "        val_indices = indices[start:stop]\n",
        "        train_indices = np.concatenate((indices[:start], indices[stop:]))\n",
        "        X_train, y_train = X[train_indices], y[train_indices]\n",
        "        X_val, y_val = X[val_indices], y[val_indices]\n",
        "        modelo.fit(X_train, y_train)\n",
        "        y_pred = modelo.predict(X_val)\n",
        "\n",
        "        accuracy = np.mean(y_pred == y_val)\n",
        "        precision = np.sum((y_pred == 1) & (y_val == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y_val == 1)) / np.sum(y_val == 1)\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        current = stop\n",
        "\n",
        "    print(\"Accuracy - Media: {:.4f}, Desviación Estándar: {:.4f}\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
        "    print(\"Precision - Media: {:.4f}, Desviación Estándar: {:.4f}\".format(np.mean(precision_scores), np.std(precision_scores)))\n",
        "    print(\"Recall - Media: {:.4f}, Desviación Estándar: {:.4f}\".format(np.mean(recall_scores), np.std(recall_scores)))\n",
        "    print(\"F1 - Media: {:.4f}, Desviación Estándar: {:.4f}\".format(np.mean(f1_scores), np.std(f1_scores)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Entrene 10 combinaciones distintas de parámetros para su implementación de Arbol de Decisión y utilizando su implementación de `validacion_cruzada`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combinación de parámetros 1:\n",
            "{'max_depth': 2, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9133, Desviación Estándar: 0.0542\n",
            "Precision - Media: 0.8316, Desviación Estándar: 0.1360\n",
            "Recall - Media: 0.9033, Desviación Estándar: 0.0897\n",
            "F1 - Media: 0.8580, Desviación Estándar: 0.0905\n",
            "\n",
            "Combinación de parámetros 2:\n",
            "{'max_depth': 2, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9267, Desviación Estándar: 0.0533\n",
            "Precision - Media: 0.8839, Desviación Estándar: 0.0896\n",
            "Recall - Media: 0.9035, Desviación Estándar: 0.1103\n",
            "F1 - Media: 0.8895, Desviación Estándar: 0.0859\n",
            "\n",
            "Combinación de parámetros 3:\n",
            "{'max_depth': 3, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9600, Desviación Estándar: 0.0327\n",
            "Precision - Media: 0.9333, Desviación Estándar: 0.0565\n",
            "Recall - Media: 0.9402, Desviación Estándar: 0.0865\n",
            "F1 - Media: 0.9347, Desviación Estándar: 0.0596\n",
            "\n",
            "Combinación de parámetros 4:\n",
            "{'max_depth': 3, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9600, Desviación Estándar: 0.0133\n",
            "Precision - Media: 0.9470, Desviación Estándar: 0.0720\n",
            "Recall - Media: 0.9386, Desviación Estándar: 0.0516\n",
            "F1 - Media: 0.9389, Desviación Estándar: 0.0211\n",
            "\n",
            "Combinación de parámetros 5:\n",
            "{'max_depth': 4, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9400, Desviación Estándar: 0.0327\n",
            "Precision - Media: 0.9147, Desviación Estándar: 0.1110\n",
            "Recall - Media: 0.9136, Desviación Estándar: 0.1079\n",
            "F1 - Media: 0.9032, Desviación Estándar: 0.0555\n",
            "\n",
            "Combinación de parámetros 6:\n",
            "{'max_depth': 4, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9400, Desviación Estándar: 0.0389\n",
            "Precision - Media: 0.8942, Desviación Estándar: 0.0825\n",
            "Recall - Media: 0.9136, Desviación Estándar: 0.1079\n",
            "F1 - Media: 0.9007, Desviación Estándar: 0.0785\n",
            "\n",
            "Combinación de parámetros 7:\n",
            "{'max_depth': 5, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9400, Desviación Estándar: 0.0490\n",
            "Precision - Media: 0.9458, Desviación Estándar: 0.0741\n",
            "Recall - Media: 0.8861, Desviación Estándar: 0.1722\n",
            "F1 - Media: 0.9001, Desviación Estándar: 0.0988\n",
            "\n",
            "Combinación de parámetros 8:\n",
            "{'max_depth': 5, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9533, Desviación Estándar: 0.0267\n",
            "Precision - Media: 0.9310, Desviación Estándar: 0.0587\n",
            "Recall - Media: 0.9396, Desviación Estándar: 0.0497\n",
            "F1 - Media: 0.9337, Desviación Estándar: 0.0382\n",
            "\n",
            "Combinación de parámetros 9:\n",
            "{'max_depth': 6, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9533, Desviación Estándar: 0.0267\n",
            "Precision - Media: 0.9194, Desviación Estándar: 0.0434\n",
            "Recall - Media: 0.9361, Desviación Estándar: 0.0539\n",
            "F1 - Media: 0.9274, Desviación Estándar: 0.0457\n",
            "\n",
            "Combinación de parámetros 10:\n",
            "{'max_depth': 6, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9467, Desviación Estándar: 0.0267\n",
            "Precision - Media: 0.9156, Desviación Estándar: 0.0821\n",
            "Recall - Media: 0.9196, Desviación Estándar: 0.0430\n",
            "F1 - Media: 0.9157, Desviación Estándar: 0.0504\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definir las combinaciones de parámetros\n",
        "param_combinations = [\n",
        "    {'max_depth': 2, 'min_split_samples': 2},\n",
        "    {'max_depth': 2, 'min_split_samples': 5},\n",
        "    {'max_depth': 3, 'min_split_samples': 2},\n",
        "    {'max_depth': 3, 'min_split_samples': 5},\n",
        "    {'max_depth': 4, 'min_split_samples': 2},\n",
        "    {'max_depth': 4, 'min_split_samples': 5},\n",
        "    {'max_depth': 5, 'min_split_samples': 2},\n",
        "    {'max_depth': 5, 'min_split_samples': 5},\n",
        "    {'max_depth': 6, 'min_split_samples': 2},\n",
        "    {'max_depth': 6, 'min_split_samples': 5}\n",
        "]\n",
        "\n",
        "# Entrenar y evaluar cada combinación de parámetros\n",
        "for i, params in enumerate(param_combinations, 1):\n",
        "    print(f\"Combinación de parámetros {i}:\")\n",
        "    print(params)\n",
        "    \n",
        "    # Crear y entrenar el árbol de decisión con los parámetros actuales\n",
        "    arbol = ArbolDecision(**params)\n",
        "    \n",
        "    # Realizar validación cruzada\n",
        "    validacion_cruzada(arbol, X, y, k=5)\n",
        "    \n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Utilizando los resultados obtenidos analice cuál y porqué es el mejor modelo para ser usado en producción.\n",
        "\n",
        "Basándonos en los resultados obtenidos de las 10 combinaciones de parámetros evaluadas mediante validación cruzada, podemos analizar cuál es el mejor modelo para ser utilizado en producción.\n",
        "\n",
        "Según los resultados, la combinación de parámetros número 4 parece ser la mejor opción. Los parámetros utilizados en esta combinación son:\n",
        "- `max_depth`: 3\n",
        "- `min_split_samples`: 5\n",
        "\n",
        "Las métricas obtenidas para esta combinación son las siguientes:\n",
        "- Accuracy - Media: 0.9600, Desviación Estándar: 0.0133\n",
        "- Precision - Media: 0.9470, Desviación Estándar: 0.0720\n",
        "- Recall - Media: 0.9386, Desviación Estándar: 0.0516\n",
        "- F1 - Media: 0.9389, Desviación Estándar: 0.0211\n",
        "\n",
        "Analizando estas métricas, podemos observar que:\n",
        "\n",
        "1. La combinación número 4 logra una alta precisión (accuracy) con una media de 0.9600 y una baja desviación estándar de 0.0133. Esto indica que el modelo tiene un buen rendimiento general y es consistente en sus predicciones.\n",
        "\n",
        "2. La precisión (precision) también es alta, con una media de 0.9470 y una desviación estándar relativamente baja de 0.0720. Esto sugiere que el modelo tiene una alta proporción de verdaderos positivos entre las instancias que predice como positivas.\n",
        "\n",
        "3. El recall también es alto, con una media de 0.9386 y una desviación estándar de 0.0516. Esto indica que el modelo es capaz de identificar correctamente una gran proporción de las instancias positivas reales.\n",
        "\n",
        "4. La puntuación F1, que es una media armónica de la precisión y el recall, también es alta con una media de 0.9389 y una desviación estándar baja de 0.0211. Esto sugiere un buen equilibrio entre la precisión y el recall.\n",
        "\n",
        "Además, la combinación número 4 utiliza una profundidad máxima (`max_depth`) de 3 y un número mínimo de muestras para dividir (`min_split_samples`) de 5. Estos parámetros evitan que el árbol de decisión sea demasiado complejo y propenso al sobreajuste, al limitar la profundidad y requerir un número mínimo de muestras para realizar una división.\n",
        "\n",
        "En comparación con las otras combinaciones de parámetros, la combinación número 4 muestra un buen equilibrio entre el rendimiento y la complejidad del modelo. Tiene métricas altas y consistentes, lo que sugiere que generalizará bien a nuevos datos.\n",
        "\n",
        "Por lo tanto, basándonos en estos resultados y análisis, se recomienda utilizar el modelo entrenado con la combinación de parámetros número 4 para su uso en producción. Este modelo ha demostrado un buen rendimiento general, una alta precisión y recall, y un buen equilibrio entre la complejidad y la capacidad de generalización.\n",
        "\n",
        "\n",
        "7. Compruebe las métricas usando el conjunto de prueba y analice el resultado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_9m6Jqr25fi"
      },
      "source": [
        "## Rúbrica para la Implementación de un Árbol de Decisión\n",
        "\n",
        "**Nota: Esta rúbrica se basa en la calidad de la implementación y los resultados obtenidos, no en la cantidad de código.**\n",
        "\n",
        "**1. Creación de la Clase Nodo (10 puntos)**\n",
        "\n",
        "- [ ] Se crea una clase `Nodo` con los atributos mencionados en las especificaciones (feature, umbral, gini, cantidad_muestras, valor, izquierda, derecha).\n",
        "- [ ] Los atributos se definen correctamente y se asignan de manera apropiada.\n",
        "\n",
        "**2. Creación de la Clase Árbol de Decisión (20 puntos)**\n",
        "\n",
        "- [ ] Se crea una clase que implementa un árbol de decisión.\n",
        "- [ ] La clase utiliza las funciones presentadas en el cuaderno.\n",
        "- [ ] Se implementan los hyperparámetros solicitados (max_depth, min_split_samples, criterio).\n",
        "- [ ] La clase es capaz de entrenar un árbol de decisión con los hyperparámetros especificados.\n",
        "\n",
        "**3. División de Datos (10 puntos)**\n",
        "\n",
        "- [ ] Los datos se dividen en conjuntos de entrenamiento y prueba de forma manual.\n",
        "- [ ] Se utiliza Numpy o Pandas para realizar esta división.\n",
        "- [ ] Se garantiza que los conjuntos sean excluyentes.\n",
        "\n",
        "**4. Implementación de Validación Cruzada (20 puntos)**\n",
        "\n",
        "- [ ] Se implementa la función `validacion_cruzada` correctamente.\n",
        "- [ ] Los datos de entrenamiento se dividen en k subconjuntos excluyentes.\n",
        "- [ ] Se entrena y evalúa un modelo para cada subconjunto de validación.\n",
        "- [ ] Se calculan y reportan las métricas de accuracy, precision, recall y F1.\n",
        "- [ ] Se calcula la media y la desviación estándar de estas métricas.\n",
        "\n",
        "**5. Entrenamiento de Modelos (20 puntos)**\n",
        "\n",
        "- [ ] Se entrenan 10 combinaciones distintas de parámetros para el árbol de decisión.\n",
        "- [ ] Cada combinación se entrena utilizando la función `validacion_cruzada`.\n",
        "- [ ] Los resultados de las métricas se registran adecuadamente.\n",
        "\n",
        "**6. Análisis de Modelos (10 puntos)**\n",
        "\n",
        "- [ ] Se analizan los resultados obtenidos y se selecciona el mejor modelo para ser utilizado en producción.\n",
        "- [ ] Se proporciona una justificación clara y fundamentada sobre por qué se eligió ese modelo.\n",
        "\n",
        "**7. Prueba en el Conjunto de Prueba (10 puntos)**\n",
        "\n",
        "- [ ] Se comprueban las métricas del modelo seleccionado utilizando el conjunto de prueba.\n",
        "- [ ] Se analizan los resultados y se comentan las conclusiones.\n",
        "\n",
        "**General (10 puntos)**\n",
        "\n",
        "- [ ] El código se documenta de manera adecuada, incluyendo comentarios que expliquen las secciones clave.\n",
        "- [ ] El código se ejecuta sin errores y sigue buenas prácticas de programación.\n",
        "- [ ] La presentación de los resultados es clara y fácil de entender.\n",
        "- [ ] Se cumple con todos los requisitos y las especificaciones proporcionadas.\n",
        "\n",
        "**Puntuación Total: 100 puntos**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
