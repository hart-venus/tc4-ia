{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eNq4lCSSQWn"
      },
      "source": [
        "**Instituto Tecnológico de Costa Rica - TEC**\n",
        "\n",
        "***Inteligencia Artificial***\n",
        "\n",
        "*Docente: Kenneth Obando Rodríguez*\n",
        "\n",
        "---\n",
        "# Trabajo Corto 3: Árboles de Decisión\n",
        "---\n",
        "Estudiantes:\n",
        "- Ariel Leyva c.2022175018\n",
        "- Mario Barboza c.2021075241\n",
        "- Camilo Sanchez c.\n",
        "- Dayron Padilla c.\n",
        "\n",
        "Link del Cuaderno (recuerde configurar el acceso a público):\n",
        "\n",
        "    \n",
        "- [Link de su respuesta](https://github.com/hart-venus/tc4-ia/)\n",
        "\n",
        "    **Nota:** Este trabajo tiene como objetivo promover la comprensión de la materia y su importancia en la elección de algoritmos. Los alumnos deben evitar copiar y pegar directamente información de fuentes externas, y en su lugar, demostrar su propio análisis y comprensión.\n",
        "\n",
        "### Entrega\n",
        "Debe entregar un archivo comprimido por el TecDigital, incluyendo un documento pdf con los resultados de los experimentos y pruebas. La fecha de entrega es el miércoles 1 de mayo a las 10:00 p.m."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmAGdF_-Xhj1"
      },
      "source": [
        "Instrucciones:\n",
        "\n",
        "Las alternativas se rifarán en clase utilizando números aleatorios. Deberá realizar la asignación propuesta. Si realiza ambos ejercicios, recibirá 20 puntos en **la nota porcentual de la actividad**, para aplicar a la totalidad de los puntos extra es necesario que ambas actividades se completen al 100%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onCmI27E3Jit"
      },
      "source": [
        "## Actividad - Taller\n",
        "\n",
        "1. Cree una clase nodo con atributos necesarios para un árbol de decisión: feature, umbral, gini, cantidad_muestras, valor, izquierda, derecha\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "class Nodo:\n",
        "    def __init__(self, feature=None, umbral=None, gini=None, cantidad_muestras=None, valor=None, izquierda=None, derecha=None):\n",
        "        self.feature = feature  # Índice de la característica (feature) para la división\n",
        "        self.umbral = umbral  # Valor umbral para la división\n",
        "        self.gini = gini  # Impureza de Gini en el nodo\n",
        "        self.cantidad_muestras = cantidad_muestras  # Cantidad de muestras en el nodo\n",
        "        self.valor = valor  # Valor de predicción (para nodos hoja)\n",
        "        self.izquierda = izquierda  # Nodo hijo izquierdo\n",
        "        self.derecha = derecha  # Nodo hijo derecho\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explicación de los atributos:\n",
        "\n",
        "- feature: Representa el índice de la característica (feature) utilizada para la división en el nodo. Es None para los nodos hoja.\n",
        "- umbral: Representa el valor umbral utilizado para la división en el nodo. Las muestras con valores menores o iguales al umbral se envían al nodo hijo izquierdo, mientras que las muestras con valores mayores se envían al nodo hijo derecho. Es None para los nodos hoja.\n",
        "- gini: Representa la impureza de Gini en el nodo, que mide la calidad de la división. Un valor de Gini más bajo indica una división más pura.\n",
        "- cantidad_muestras: Representa la cantidad de muestras que llegan al nodo durante el entrenamiento del árbol.\n",
        "- valor: Representa el valor de predicción para los nodos hoja. En un árbol de clasificación, suele ser la clase mayoritaria entre las muestras que llegan al nodo hoja. En un árbol de regresión, puede ser el promedio de los valores de las muestras en el nodo hoja.\n",
        "- izquierda: Representa el nodo hijo izquierdo, que contiene las muestras con valores menores o iguales al umbral de división. Es None para los nodos hoja.\n",
        "- derecha: Representa el nodo hijo derecho, que contiene las muestras con valores mayores al umbral de división. Es None para los nodos hoja.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Crea una clase que implementa un árbol de decisión, utilice las funciones presentadas en clase, además incluya los siguientes hyperparámetros:\n",
        "   - max_depth: Cantidad máxima de variables que se pueden explorar\n",
        "   - min_split_samples: Cantidad mínima de muestras que deberá tener un nodo para poder ser dividido\n",
        "   - criterio: función que se utilizará para calcular la impuridad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ArbolDecision:\n",
        "    def __init__(self, max_depth=None, min_split_samples=2, criterio='gini'):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_split_samples = min_split_samples\n",
        "        self.criterio = criterio\n",
        "        self.root = None\n",
        "\n",
        "    def _calcular_gini(self, y):\n",
        "        _, counts = np.unique(y, return_counts=True) # cuenta las ocurrencias de cada clase\n",
        "        proporciones = counts / len(y) # calcula la proporción de cada clase\n",
        "        gini = 1 - np.sum(proporciones ** 2) # calcula la impureza de Gini\n",
        "        return gini \n",
        "\n",
        "    def _dividir(self, X, y, feature, umbral):\n",
        "        izquierda_indices = X[:, feature] <= umbral\n",
        "        derecha_indices = X[:, feature] > umbral # Divide basado en los umbrales\n",
        "        X_izquierda, y_izquierda = X[izquierda_indices], y[izquierda_indices]\n",
        "        X_derecha, y_derecha = X[derecha_indices], y[derecha_indices]\n",
        "        return X_izquierda, y_izquierda, X_derecha, y_derecha\n",
        "\n",
        "    def _construir_arbol(self, X, y, depth=0):\n",
        "        cantidad_muestras = len(y)\n",
        "        if cantidad_muestras < self.min_split_samples or depth == self.max_depth: # caso base\n",
        "            valor = np.bincount(y).argmax()\n",
        "            return Nodo(cantidad_muestras=cantidad_muestras, valor=valor)\n",
        "\n",
        "        mejor_feature, mejor_umbral, mejor_gini = None, None, float('inf')\n",
        "        for feature in range(X.shape[1]):\n",
        "            umbrales = np.unique(X[:, feature])\n",
        "            for umbral in umbrales: # construye el arbol por cada umbral\n",
        "                X_izquierda, y_izquierda, X_derecha, y_derecha = self._dividir(X, y, feature, umbral)\n",
        "                if len(y_izquierda) > 0 and len(y_derecha) > 0: # si hay muestras en ambos nodos hijos\n",
        "                    gini_izquierda = self._calcular_gini(y_izquierda)\n",
        "                    gini_derecha = self._calcular_gini(y_derecha)\n",
        "                    gini = (len(y_izquierda) * gini_izquierda + len(y_derecha) * gini_derecha) / cantidad_muestras\n",
        "                    if gini < mejor_gini:\n",
        "                        mejor_feature, mejor_umbral, mejor_gini = feature, umbral, gini\n",
        "\n",
        "        if mejor_feature is None: # si no se puede dividir, caso base\n",
        "            valor = np.bincount(y).argmax()\n",
        "            return Nodo(cantidad_muestras=cantidad_muestras, valor=valor)\n",
        "\n",
        "        X_izquierda, y_izquierda, X_derecha, y_derecha = self._dividir(X, y, mejor_feature, mejor_umbral)\n",
        "        nodo_izquierdo = self._construir_arbol(X_izquierda, y_izquierda, depth + 1) # crear hijos recursivamente\n",
        "        nodo_derecho = self._construir_arbol(X_derecha, y_derecha, depth + 1)\n",
        "\n",
        "        return Nodo(feature=mejor_feature, umbral=mejor_umbral, gini=mejor_gini,\n",
        "                    cantidad_muestras=cantidad_muestras, izquierda=nodo_izquierdo, derecha=nodo_derecho)\n",
        "\n",
        "    def fit(self, X, y): # metodo publico para entrenar el modelo\n",
        "        self.root = self._construir_arbol(X, y)\n",
        "\n",
        "    def _predecir(self, x, nodo): \n",
        "        if nodo.valor is not None:\n",
        "            return nodo.valor\n",
        "        if x[nodo.feature] <= nodo.umbral:\n",
        "            return self._predecir(x, nodo.izquierda)\n",
        "        else:\n",
        "            return self._predecir(x, nodo.derecha)\n",
        "\n",
        "    def predict(self, X): # metodo publico para hacer predicciones\n",
        "        return np.array([self._predecir(x, self.root) for x in X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Divida los datos en los conjuntos tradicionales de entrenamiento y prueba, de forma manual, sin utilizar las utilidades de sklearn (puede utilizar índices de Numpy o Pandas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar datos de prueba (Iris dataset)\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba utilizando índices de NumPy\n",
        "indices = np.arange(len(X))\n",
        "np.random.shuffle(indices)\n",
        "train_size = int(0.8 * len(X))\n",
        "train_indices = indices[:train_size]\n",
        "test_indices = indices[train_size:]\n",
        "X_train, y_train = X[train_indices], y[train_indices]\n",
        "X_test, y_test = X[test_indices], y[test_indices]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Implemente una función que se llame `validacion_cruzada` que entrene $k$ modelos y reporte las métricas obtenidas:\n",
        "  a. Divida el conjunto de entrenamiento en $k$ subconjuntos excluyentes\n",
        "  b. Para cada uno de los $k$ modelos, utilice un subconjunto como validación\n",
        "  c. Reporte la media y la desviación estándar para cada una de las métricas, todo debe realizarse solo usando Numpy:\n",
        "    - Accuracy\n",
        "    - Precision\n",
        "    - Recall\n",
        "    - F1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validacion_cruzada(modelo, X, y, k=5):\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    fold_sizes = np.full(k, len(X) // k, dtype=int)\n",
        "    fold_sizes[:len(X) % k] += 1\n",
        "    current = 0\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for fold_size in fold_sizes:\n",
        "        start, stop = current, current + fold_size\n",
        "        val_indices = indices[start:stop]\n",
        "        train_indices = np.concatenate((indices[:start], indices[stop:]))\n",
        "        X_train, y_train = X[train_indices], y[train_indices]\n",
        "        X_val, y_val = X[val_indices], y[val_indices]\n",
        "        modelo.fit(X_train, y_train)\n",
        "        y_pred = modelo.predict(X_val)\n",
        "\n",
        "        accuracy = np.mean(y_pred == y_val)\n",
        "        precision = np.sum((y_pred == 1) & (y_val == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y_val == 1)) / np.sum(y_val == 1)\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        current = stop\n",
        "\n",
        "    print(\"Accuracy - Media: {:.4f}, Desviación Estándar: {:.4f}\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
        "    print(\"Precision - Media: {:.4f}, Desviación Estándar: {:.4f}\".format(np.mean(precision_scores), np.std(precision_scores)))\n",
        "    print(\"Recall - Media: {:.4f}, Desviación Estándar: {:.4f}\".format(np.mean(recall_scores), np.std(recall_scores)))\n",
        "    print(\"F1 - Media: {:.4f}, Desviación Estándar: {:.4f}\".format(np.mean(f1_scores), np.std(f1_scores)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Entrene 10 combinaciones distintas de parámetros para su implementación de Arbol de Decisión y utilizando su implementación de `validacion_cruzada`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combinación de parámetros 1:\n",
            "{'max_depth': 2, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9250, Desviación Estándar: 0.0486\n",
            "Precision - Media: 0.8964, Desviación Estándar: 0.0948\n",
            "Recall - Media: 0.8929, Desviación Estándar: 0.1723\n",
            "F1 - Media: 0.8760, Desviación Estándar: 0.0870\n",
            "\n",
            "Combinación de parámetros 2:\n",
            "{'max_depth': 2, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9167, Desviación Estándar: 0.0456\n",
            "Precision - Media: 0.8572, Desviación Estándar: 0.0786\n",
            "Recall - Media: 0.9083, Desviación Estándar: 0.0841\n",
            "F1 - Media: 0.8784, Desviación Estándar: 0.0550\n",
            "\n",
            "Combinación de parámetros 3:\n",
            "{'max_depth': 3, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9167, Desviación Estándar: 0.0745\n",
            "Precision - Media: 0.8643, Desviación Estándar: 0.1567\n",
            "Recall - Media: 0.9073, Desviación Estándar: 0.1409\n",
            "F1 - Media: 0.8690, Desviación Estándar: 0.1140\n",
            "\n",
            "Combinación de parámetros 4:\n",
            "{'max_depth': 3, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9500, Desviación Estándar: 0.0312\n",
            "Precision - Media: 0.9400, Desviación Estándar: 0.0800\n",
            "Recall - Media: 0.9214, Desviación Estándar: 0.1020\n",
            "F1 - Media: 0.9233, Desviación Estándar: 0.0490\n",
            "\n",
            "Combinación de parámetros 5:\n",
            "{'max_depth': 4, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9417, Desviación Estándar: 0.0624\n",
            "Precision - Media: 0.8961, Desviación Estándar: 0.1661\n",
            "Recall - Media: 0.9196, Desviación Estándar: 0.0752\n",
            "F1 - Media: 0.9034, Desviación Estándar: 0.1234\n",
            "\n",
            "Combinación de parámetros 6:\n",
            "{'max_depth': 4, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9083, Desviación Estándar: 0.0486\n",
            "Precision - Media: 0.8425, Desviación Estándar: 0.1637\n",
            "Recall - Media: 0.9056, Desviación Estándar: 0.0923\n",
            "F1 - Media: 0.8571, Desviación Estándar: 0.0881\n",
            "\n",
            "Combinación de parámetros 7:\n",
            "{'max_depth': 5, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9250, Desviación Estándar: 0.0167\n",
            "Precision - Media: 0.9192, Desviación Estándar: 0.0709\n",
            "Recall - Media: 0.8556, Desviación Estándar: 0.1089\n",
            "F1 - Media: 0.8774, Desviación Estándar: 0.0394\n",
            "\n",
            "Combinación de parámetros 8:\n",
            "{'max_depth': 5, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9583, Desviación Estándar: 0.0264\n",
            "Precision - Media: 0.9492, Desviación Estándar: 0.0630\n",
            "Recall - Media: 0.9000, Desviación Estándar: 0.1549\n",
            "F1 - Media: 0.9123, Desviación Estándar: 0.0851\n",
            "\n",
            "Combinación de parámetros 9:\n",
            "{'max_depth': 6, 'min_split_samples': 2}\n",
            "Accuracy - Media: 0.9417, Desviación Estándar: 0.0333\n",
            "Precision - Media: 0.9000, Desviación Estándar: 0.1333\n",
            "Recall - Media: 0.9303, Desviación Estándar: 0.0633\n",
            "F1 - Media: 0.9046, Desviación Estándar: 0.0558\n",
            "\n",
            "Combinación de parámetros 10:\n",
            "{'max_depth': 6, 'min_split_samples': 5}\n",
            "Accuracy - Media: 0.9417, Desviación Estándar: 0.0565\n",
            "Precision - Media: 0.9083, Desviación Estándar: 0.0841\n",
            "Recall - Media: 0.9306, Desviación Estándar: 0.0904\n",
            "F1 - Media: 0.9176, Desviación Estándar: 0.0798\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definir las combinaciones de parámetros\n",
        "param_combinations = [\n",
        "    {'max_depth': 2, 'min_split_samples': 2},\n",
        "    {'max_depth': 2, 'min_split_samples': 5},\n",
        "    {'max_depth': 3, 'min_split_samples': 2},\n",
        "    {'max_depth': 3, 'min_split_samples': 5},\n",
        "    {'max_depth': 4, 'min_split_samples': 2},\n",
        "    {'max_depth': 4, 'min_split_samples': 5},\n",
        "    {'max_depth': 5, 'min_split_samples': 2},\n",
        "    {'max_depth': 5, 'min_split_samples': 5},\n",
        "    {'max_depth': 6, 'min_split_samples': 2},\n",
        "    {'max_depth': 6, 'min_split_samples': 5}\n",
        "]\n",
        "\n",
        "# Entrenar y evaluar cada combinación de parámetros\n",
        "for i, params in enumerate(param_combinations, 1):\n",
        "    print(f\"Combinación de parámetros {i}:\")\n",
        "    print(params)\n",
        "    \n",
        "    # Crear y entrenar el árbol de decisión con los parámetros actuales\n",
        "    arbol = ArbolDecision(**params)\n",
        "    \n",
        "    # Realizar validación cruzada\n",
        "    validacion_cruzada(arbol, X_train, y_train, k=5)\n",
        "    \n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Utilizando los resultados obtenidos analice cuál y porqué es el mejor modelo para ser usado en producción.\n",
        "\n",
        "Basándonos en los resultados obtenidos de las 10 combinaciones de parámetros evaluadas mediante validación cruzada, podemos analizar cuál es el mejor modelo para ser utilizado en producción. Según los resultados, la combinación de parámetros número 4 parece ser la mejor opción. Los parámetros utilizados en esta combinación son:\n",
        "\n",
        "-  max_depth: 3\n",
        "- min_split_samples: 5\n",
        "\n",
        "Las métricas obtenidas para esta combinación son las siguientes:\n",
        "\n",
        "- Accuracy - Media: 0.9500, Desviación Estándar: 0.0312\n",
        "- Precision - Media: 0.9400, Desviación Estándar: 0.0800\n",
        "- Recall - Media: 0.9214, Desviación Estándar: 0.1020\n",
        "- F1 - Media: 0.9233, Desviación Estándar: 0.0490\n",
        "\n",
        "Analizando estas métricas, podemos observar que:\n",
        "\n",
        "- La combinación número 4 tiene el valor más alto de accuracy (0.9500) entre todas las combinaciones evaluadas. Esto indica que el modelo clasifica correctamente el 95% de las instancias en promedio.\n",
        "-  La precision también es alta (0.9400), lo que significa que cuando el modelo predice una clase positiva, tiene una alta probabilidad de ser correcta. En otras palabras, el modelo tiene una baja tasa de falsos positivos.\n",
        "-  El recall es igualmente alto (0.9214), lo que indica que el modelo es capaz de identificar correctamente una gran proporción de las instancias positivas reales. Esto sugiere que el modelo tiene una baja tasa de falsos negativos.\n",
        "-  El valor F1, que es una media armónica de precision y recall, también es alto (0.9233), lo que indica un buen equilibrio entre precision y recall.\n",
        "\n",
        "Además, las desviaciones estándar de las métricas para esta combinación son relativamente bajas en comparación con otras combinaciones, lo que sugiere una menor variabilidad en el rendimiento del modelo a través de los diferentes pliegues de la validación cruzada. \n",
        "\n",
        "7. Compruebe las métricas usando el conjunto de prueba y analice el resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy - Media: 0.9000, Desviación Estándar: 0.0816\n",
            "Precision - Media: 0.8000, Desviación Estándar: 0.2449\n",
            "Recall - Media: 0.9500, Desviación Estándar: 0.1000\n",
            "F1 - Media: 0.8381, Desviación Estándar: 0.1494\n"
          ]
        }
      ],
      "source": [
        "arbol = ArbolDecision(max_depth=3, min_split_samples=5)\n",
        "validacion_cruzada(arbol, X_test, y_test, k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, analizando los resultados obtenidos en el subconjunto de prueba para la combinación de parámetros seleccionada (combinación número 4), podemos observar lo siguiente:\n",
        "\n",
        "1. Accuracy - Media: 0.9000, Desviación Estándar: 0.0816\n",
        "   - La accuracy media en el subconjunto de prueba es del 90%, lo que indica que el modelo clasifica correctamente el 90% de las instancias en promedio.\n",
        "   - La desviación estándar de la accuracy es de 0.0816, lo que sugiere una variabilidad moderada en el rendimiento del modelo en el subconjunto de prueba.\n",
        "\n",
        "2. Precision - Media: 0.8000, Desviación Estándar: 0.2449\n",
        "   - La precision media en el subconjunto de prueba es del 80%, lo que significa que cuando el modelo predice una clase positiva, tiene una probabilidad del 80% de ser correcta.\n",
        "   - La desviación estándar de la precision es de 0.2449, lo que indica una mayor variabilidad en la precision del modelo en el subconjunto de prueba en comparación con la validación cruzada.\n",
        "\n",
        "3. Recall - Media: 0.9500, Desviación Estándar: 0.1000\n",
        "   - El recall medio en el subconjunto de prueba es del 95%, lo que indica que el modelo es capaz de identificar correctamente el 95% de las instancias positivas reales.\n",
        "   - La desviación estándar del recall es de 0.1000, lo que sugiere una variabilidad moderada en el recall del modelo en el subconjunto de prueba.\n",
        "\n",
        "4. F1 - Media: 0.8381, Desviación Estándar: 0.1494\n",
        "   - El valor F1 medio en el subconjunto de prueba es de 0.8381, lo que indica un buen equilibrio entre precision y recall.\n",
        "   - La desviación estándar del valor F1 es de 0.1494, lo que sugiere una variabilidad moderada en el rendimiento general del modelo en el subconjunto de prueba.\n",
        "\n",
        "Comparando estos resultados con los obtenidos en la validación cruzada, podemos observar algunas diferencias:\n",
        "\n",
        "- La accuracy media en el subconjunto de prueba (0.9000) es ligeramente inferior a la obtenida en la validación cruzada (0.9500), lo que sugiere un rendimiento un poco menor en datos no vistos.\n",
        "- La precision media en el subconjunto de prueba (0.8000) es considerablemente menor que la obtenida en la validación cruzada (0.9400), lo que indica una mayor tasa de falsos positivos en el subconjunto de prueba.\n",
        "- El recall medio en el subconjunto de prueba (0.9500) es ligeramente superior al obtenido en la validación cruzada (0.9214), lo que sugiere una mejor capacidad para identificar instancias positivas reales en el subconjunto de prueba.\n",
        "- El valor F1 medio en el subconjunto de prueba (0.8381) es menor que el obtenido en la validación cruzada (0.9233), lo que indica un rendimiento general un poco inferior en el subconjunto de prueba.\n",
        "\n",
        "Estas diferencias pueden deberse a la variabilidad inherente en los datos y al hecho de que el subconjunto de prueba contiene datos no vistos durante el entrenamiento y la validación cruzada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_9m6Jqr25fi"
      },
      "source": [
        "## Rúbrica para la Implementación de un Árbol de Decisión\n",
        "\n",
        "**Nota: Esta rúbrica se basa en la calidad de la implementación y los resultados obtenidos, no en la cantidad de código.**\n",
        "\n",
        "**1. Creación de la Clase Nodo (10 puntos)**\n",
        "\n",
        "- [ ] Se crea una clase `Nodo` con los atributos mencionados en las especificaciones (feature, umbral, gini, cantidad_muestras, valor, izquierda, derecha).\n",
        "- [ ] Los atributos se definen correctamente y se asignan de manera apropiada.\n",
        "\n",
        "**2. Creación de la Clase Árbol de Decisión (20 puntos)**\n",
        "\n",
        "- [ ] Se crea una clase que implementa un árbol de decisión.\n",
        "- [ ] La clase utiliza las funciones presentadas en el cuaderno.\n",
        "- [ ] Se implementan los hyperparámetros solicitados (max_depth, min_split_samples, criterio).\n",
        "- [ ] La clase es capaz de entrenar un árbol de decisión con los hyperparámetros especificados.\n",
        "\n",
        "**3. División de Datos (10 puntos)**\n",
        "\n",
        "- [ ] Los datos se dividen en conjuntos de entrenamiento y prueba de forma manual.\n",
        "- [ ] Se utiliza Numpy o Pandas para realizar esta división.\n",
        "- [ ] Se garantiza que los conjuntos sean excluyentes.\n",
        "\n",
        "**4. Implementación de Validación Cruzada (20 puntos)**\n",
        "\n",
        "- [ ] Se implementa la función `validacion_cruzada` correctamente.\n",
        "- [ ] Los datos de entrenamiento se dividen en k subconjuntos excluyentes.\n",
        "- [ ] Se entrena y evalúa un modelo para cada subconjunto de validación.\n",
        "- [ ] Se calculan y reportan las métricas de accuracy, precision, recall y F1.\n",
        "- [ ] Se calcula la media y la desviación estándar de estas métricas.\n",
        "\n",
        "**5. Entrenamiento de Modelos (20 puntos)**\n",
        "\n",
        "- [ ] Se entrenan 10 combinaciones distintas de parámetros para el árbol de decisión.\n",
        "- [ ] Cada combinación se entrena utilizando la función `validacion_cruzada`.\n",
        "- [ ] Los resultados de las métricas se registran adecuadamente.\n",
        "\n",
        "**6. Análisis de Modelos (10 puntos)**\n",
        "\n",
        "- [ ] Se analizan los resultados obtenidos y se selecciona el mejor modelo para ser utilizado en producción.\n",
        "- [ ] Se proporciona una justificación clara y fundamentada sobre por qué se eligió ese modelo.\n",
        "\n",
        "**7. Prueba en el Conjunto de Prueba (10 puntos)**\n",
        "\n",
        "- [ ] Se comprueban las métricas del modelo seleccionado utilizando el conjunto de prueba.\n",
        "- [ ] Se analizan los resultados y se comentan las conclusiones.\n",
        "\n",
        "**General (10 puntos)**\n",
        "\n",
        "- [ ] El código se documenta de manera adecuada, incluyendo comentarios que expliquen las secciones clave.\n",
        "- [ ] El código se ejecuta sin errores y sigue buenas prácticas de programación.\n",
        "- [ ] La presentación de los resultados es clara y fácil de entender.\n",
        "- [ ] Se cumple con todos los requisitos y las especificaciones proporcionadas.\n",
        "\n",
        "**Puntuación Total: 100 puntos**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
